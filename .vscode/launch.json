{
    // 使用 IntelliSense 了解相关属性。 
    // 悬停以查看现有属性的描述。
    // 欲了解更多信息，请访问: https://go.microsoft.com/fwlink/?linkid=830387
    "version": "0.2.0",
    "configurations": [
        {
            "name": "My Train",
            "type": "debugpy",
            "request": "launch",
            "program": "/data/huengchi/bin/miniconda3/envs/py-3.10-torch-2.1/bin/deepspeed",
            // "program": "main_sft.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--master_port", "39285",
                "--include=localhost:0,1,2,3",
                // "--include=localhost:0",
                "main_sft.py",
                "--learning_rate", "5e-6",
                // "--model_name_or_path", "/home/models/Llama-2-7b-hf",
                "--model_name_or_path", "/home/models/Mistral-7B-v0.1/",
                "--custom_local_dataset", "datasets/mimic-iii-notes/LLM_FT_Dataset_len8K_cov0.5_w_ESGs.jsonl",
                "--dataset_sample", "1000",
                "--fed_alg", "fedavg",
                "--num_clients", "1",
                "--sample_clients", "1",
                "--max_steps", "1000",
                "--num_rounds", "1",
                "--batch_size", "1",
                "--gradient_accumulation_steps", "16",
                "--seq_length", "8192",
                "--peft_lora_r", "32",
                "--peft_lora_alpha", "64",
                "--use_peft",
                "--output_dir", "./output",
                "--template", "alpaca",
                // "--load_in_8bit", // useful for inference only, not the same as 8-bit Adam optimizer
                "--deepspeed", "default_ds_zero_stage2_offload.json",
                "--gradient_checkpointing", "true",
                "--bf16", "true",
                "--optim", "adamw_bnb_8bit",
                "--flash_attention"
            ],
            "env": {
                // "CUDA_VISIBLE_DEVICES": "1",
                "http_proxy": "http://10.249.42.241:41122",
                "https_proxy": "http://10.249.42.241:41122",
            }
        },
        {
            "name": "My Predict",
            "type": "debugpy",
            "request": "launch",
            "cwd": "${workspaceFolder}/evaluation/legal/",
            "program": "predict.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--base_model_path", "/home/models/Llama-2-7b-hf",
                "--template", "alpaca",
                "--lora_path", "../../output/CodeAlpaca-20k_1000_fedavg_c1s1_i1000_b1a1_l8192_r32a64_20240315132536/checkpoint-r1-s1000",
                "--test_set_path", "../../datasets/DISC-Law-SFT/jud_doc_sum/jud_doc_sum_test_split.jsonl",
                "--output_dir", "./prediction_output",
                "--max_new_token", "2048",
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://10.249.42.241:41122",
                "https_proxy": "http://10.249.42.241:41122",
            }
        },
        {
            "name": "My Score",
            "type": "debugpy",
            "request": "launch",
            "cwd": "${workspaceFolder}/evaluation/legal/",
            "program": "score.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--prediction_set_path", "prediction_output/20240315163646.jsonl",
                "--test_set_path", "../../datasets/DISC-Law-SFT/jud_doc_sum/jud_doc_sum_test_split.jsonl",
                "--output_dir", "score_output"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://10.249.42.241:41122",
                "https_proxy": "http://10.249.42.241:41122",
            }
        },
        {
            "name": "Predict MT",
            "type": "debugpy",
            "request": "launch",
            "cwd": "${workspaceFolder}/evaluation/open_ended/",
            "program": "gen_model_answer_mt.py",
            "console": "integratedTerminal",
            "justMyCode": false,
            "args": [
                "--base_model_path", "/home/models/Llama-2-7b-hf",
                "--template", "alpaca",
                "--lora_path", "../../output/alpaca-gpt4_20000_fedavg_c20s2_i5_b1a1_l512_r32a64_20240314221104/checkpoint-1"
            ],
            "env": {
                "CUDA_VISIBLE_DEVICES": "0",
                "http_proxy": "http://10.249.42.241:41122",
                "https_proxy": "http://10.249.42.241:41122",
            }
        },

    ]
}